modelEmbeddings: "sentence-transformers/all-MiniLM-L6-v2"
autoTokenizer: "meta-llama/Meta-Llama-3-8B"
autoModelForCausalLM: "QuantFactory/Meta-Llama-3-8B-GGUF"
modelfile: "Meta-Llama-3-8B.Q4_K_M.gguf"
modeltype: "llama"
flask: "localhost:80"